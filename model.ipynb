{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Import các thư viện cần thiết***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Setting biến***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting model name\n",
    "tflite_model_name = \"disease_prediction_model\" # .tflite suffix\n",
    "c_model_name = 'disease_prediction_model' # .h suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Đọc data từ file***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc dữ liệu từ các file đã tạo\n",
    "train_df = pd.read_csv(\"heart_spo2_train.csv\")\n",
    "val_df = pd.read_csv(\"heart_spo2_validation.csv\")\n",
    "test_df = pd.read_csv(\"heart_spo2_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Chuẩn hóa dữ liệu***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gộp tất cả dữ liệu để chuẩn hóa\n",
    "full_df = pd.concat([train_df, val_df, test_df])\n",
    "X_full = full_df[[\"Heart Rate\", \"Oxygen Saturation\"]].values\n",
    "y_full = full_df[\"Label\"].values\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "scaler = StandardScaler()\n",
    "X_full = scaler.fit_transform(X_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Xác định kích thước từng tập và scaler***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kích thước tập train: (12000, 2)\n",
      "Kích thước tập validation: (4000, 2)\n",
      "Kích thước tập test: (4000, 2)\n",
      "Scaler mean: [84.50905    93.29880835]\n",
      "Scaler scale: [31.49859867  5.77284963]\n"
     ]
    }
   ],
   "source": [
    "# Lấy lại dữ liệu train, validation, test từ dữ liệu đã chuẩn hóa\n",
    "train_size = len(train_df)\n",
    "val_size = len(val_df)\n",
    "test_size = len(test_df)\n",
    "\n",
    "X_train, X_val, X_test = X_full[:train_size], X_full[train_size:train_size+val_size], X_full[train_size+val_size:]\n",
    "y_train, y_val, y_test = y_full[:train_size], y_full[train_size:train_size+val_size], y_full[train_size+val_size:]\n",
    "\n",
    "# Kiểm tra kích thước tập dữ liệu\n",
    "print(f\"Kích thước tập train: {X_train.shape}\")\n",
    "print(f\"Kích thước tập validation: {X_val.shape}\")\n",
    "print(f\"Kích thước tập test: {X_test.shape}\")\n",
    "\n",
    "# Kiểm tra scaler\n",
    "print(\"Scaler mean:\", scaler.mean_)\n",
    "print(\"Scaler scale:\", scaler.scale_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Xây dựng mô hình cho phân loại đa lớp (multi-class)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(2,)),   \n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Biên dịch mô hình với optimizer tùy chỉnh***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='sparse_categorical_crossentropy',  # Loss cho multi-class\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Thêm Early Stopping***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    patience=10,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Huấn luyện mô hình***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "188/188 [==============================] - 2s 4ms/step - loss: 0.1473 - accuracy: 0.9554 - val_loss: 0.0576 - val_accuracy: 0.9787\n",
      "Epoch 2/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0342 - accuracy: 0.9881 - val_loss: 0.0337 - val_accuracy: 0.9865\n",
      "Epoch 3/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9927 - val_loss: 0.0224 - val_accuracy: 0.9915\n",
      "Epoch 4/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9944 - val_loss: 0.0141 - val_accuracy: 0.9960\n",
      "Epoch 5/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 0.0187 - val_accuracy: 0.9933\n",
      "Epoch 6/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 0.9958 - val_loss: 0.0125 - val_accuracy: 0.9945\n",
      "Epoch 7/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9948 - val_loss: 0.0098 - val_accuracy: 0.9983\n",
      "Epoch 8/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0118 - val_accuracy: 0.9973\n",
      "Epoch 9/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9957 - val_loss: 0.0094 - val_accuracy: 0.9967\n",
      "Epoch 10/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 0.9967 - val_loss: 0.0060 - val_accuracy: 0.9980\n",
      "Epoch 11/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0083 - val_accuracy: 0.9975\n",
      "Epoch 12/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 0.9973 - val_loss: 0.0063 - val_accuracy: 0.9977\n",
      "Epoch 13/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 0.9979 - val_loss: 0.0054 - val_accuracy: 0.9977\n",
      "Epoch 14/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9977 - val_loss: 0.0041 - val_accuracy: 0.9983\n",
      "Epoch 15/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.0095 - val_accuracy: 0.9967\n",
      "Epoch 16/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0106 - val_accuracy: 0.9950\n",
      "Epoch 17/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0066 - val_accuracy: 0.9987\n",
      "Epoch 18/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0049 - val_accuracy: 0.9985\n",
      "Epoch 19/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9977 - val_loss: 0.0037 - val_accuracy: 0.9980\n",
      "Epoch 20/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 0.9968 - val_loss: 0.0064 - val_accuracy: 0.9977\n",
      "Epoch 21/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 0.9974 - val_loss: 0.0050 - val_accuracy: 0.9983\n",
      "Epoch 22/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0037 - val_accuracy: 0.9992\n",
      "Epoch 23/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 24/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0086 - val_accuracy: 0.9975\n",
      "Epoch 25/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0030 - val_accuracy: 0.9995\n",
      "Epoch 26/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 27/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 0.9971 - val_loss: 0.0108 - val_accuracy: 0.9967\n",
      "Epoch 28/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9974 - val_loss: 0.0037 - val_accuracy: 0.9987\n",
      "Epoch 29/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9974 - val_loss: 0.0150 - val_accuracy: 0.9893\n",
      "Epoch 30/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "Epoch 31/100\n",
      "188/188 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9983 - val_loss: 0.0069 - val_accuracy: 0.9990\n",
      "Epoch 32/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "Epoch 33/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.0056 - val_accuracy: 0.9983\n",
      "Epoch 34/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 0.9983 - val_loss: 0.0079 - val_accuracy: 0.9970\n",
      "Epoch 35/100\n",
      "188/188 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.0023 - val_accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Đánh giá mô hình trên tập test***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 0.9995\n",
      "Test Loss: 0.0028953542932868004, Test Accuracy: 0.9994999766349792\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Dự đoán trên tập test***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 0s 1ms/step\n",
      "Dự đoán nhãn (10 mẫu đầu tiên): [1 0 1 0 0 1 1 1 1 1]\n",
      "Nhãn thực tế (10 mẫu đầu tiên): [1 0 1 0 0 1 1 1 1 1]\n",
      "Độ chính xác trên tập test: 0.9995\n"
     ]
    }
   ],
   "source": [
    "# Dự đoán trên tập test\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Chuyển từ xác suất sang nhãn lớp\n",
    "\n",
    "# In ra một số kết quả dự đoán đầu tiên\n",
    "print(\"Dự đoán nhãn (10 mẫu đầu tiên):\", y_pred_classes[:10])\n",
    "print(\"Nhãn thực tế (10 mẫu đầu tiên):\", y_test[:10])\n",
    "\n",
    "# Đánh giá độ chính xác\n",
    "accuracy = np.mean(y_pred_classes == y_test)\n",
    "print(f\"Độ chính xác trên tập test: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Lưu mô hình thành file .tflite***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\vuquo\\AppData\\Local\\Temp\\tmpxdb0fsug\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\vuquo\\AppData\\Local\\Temp\\tmpxdb0fsug\\assets\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n",
      "WARNING:absl:Optimization option OPTIMIZE_FOR_SIZE is deprecated, please use optimizations=[Optimize.DEFAULT] instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3648"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]  # Giảm kích thước model\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "open(tflite_model_name + '.tflite', 'wb').write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function: Convert some hex value into an array for C programming\n",
    "def hex_to_c_array(hex_data, var_name):\n",
    "\n",
    "  c_str = ''\n",
    "\n",
    "  # Create header guard\n",
    "  c_str += '#ifndef ' + var_name.upper() + '_H\\n'\n",
    "  c_str += '#define ' + var_name.upper() + '_H\\n\\n'\n",
    "\n",
    "  # Add array length at top of file\n",
    "  c_str += '\\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\\n'\n",
    "\n",
    "  # Declare C variable\n",
    "  c_str += 'unsigned char ' + var_name + '[] = {'\n",
    "  hex_array = []\n",
    "  for i, val in enumerate(hex_data) :\n",
    "\n",
    "    # Construct string from hex\n",
    "    hex_str = format(val, '#04x')\n",
    "\n",
    "    # Add formatting so each line stays within 80 characters\n",
    "    if (i + 1) < len(hex_data):\n",
    "      hex_str += ','\n",
    "    if (i + 1) % 12 == 0:\n",
    "      hex_str += '\\n '\n",
    "    hex_array.append(hex_str)\n",
    "\n",
    "  # Add closing brace\n",
    "  c_str += '\\n ' + format(' '.join(hex_array)) + '\\n};\\n\\n'\n",
    "\n",
    "  # Close out header guard\n",
    "  c_str += '#endif //' + var_name.upper() + '_H'\n",
    "\n",
    "  return c_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write TFLite model to a C source (or header) file\n",
    "with open(c_model_name + '.h', 'w') as file:\n",
    "  file.write(hex_to_c_array(tflite_model, c_model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing multiple samples:\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [70. 98.], Scaled: [-0.46062526  0.81436235]\n",
      "Predicted: Bình thường\n",
      "Probabilities: [9.9998581e-01 1.2891178e-05 5.7135094e-07 6.4931271e-07]\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [80. 95.], Scaled: [-0.1431508   0.29468837]\n",
      "Predicted: Bình thường\n",
      "Probabilities: [9.6627486e-01 3.3719037e-02 2.6479702e-06 3.4052562e-06]\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [90. 85.], Scaled: [ 0.17432363 -1.4375583 ]\n",
      "Predicted: Bất ổn\n",
      "Probabilities: [0. 1. 0. 0.]\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [60. 90.], Scaled: [-0.7780997 -0.571435 ]\n",
      "Predicted: Bất ổn\n",
      "Probabilities: [2.1695616e-29 1.0000000e+00 3.1646829e-32 2.8072636e-32]\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [100.  92.], Scaled: [ 0.49179804 -0.22498566]\n",
      "Predicted: Bất ổn\n",
      "Probabilities: [2.5565507e-24 1.0000000e+00 3.4665830e-27 6.0456609e-27]\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [85. 99.], Scaled: [0.01558641 0.98758703]\n",
      "Predicted: Bình thường\n",
      "Probabilities: [9.9999869e-01 1.2688803e-06 3.9542534e-09 5.2529323e-09]\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [55. 88.], Scaled: [-0.9368369 -0.9178844]\n",
      "Predicted: Bất ổn\n",
      "Probabilities: [0. 1. 0. 0.]\n",
      "--------------------------------------------------------------------------------\n",
      "Input: [95. 80.], Scaled: [ 0.33306083 -2.3036816 ]\n",
      "Predicted: Bất ổn\n",
      "Probabilities: [0. 1. 0. 0.]\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Thử 1 vài test case\n",
    "tflite_model_path = \"disease_prediction_model.tflite\"\n",
    "interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "\n",
    "labels = [ \"Bình thường\", \n",
    "    \"Bất ổn\"]\n",
    "\n",
    "test_samples = np.array([\n",
    "    [70, 98], [80, 95], [90, 85], [60, 90], [100, 92], [85, 99], [55, 88], [95, 80]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(\"Testing multiple samples:\")\n",
    "print(\"-\" * 80)\n",
    "for sample in test_samples:\n",
    "    sample_scaled = scaler.transform(sample.reshape(1, -1))\n",
    "    interpreter.set_tensor(input_details[0]['index'], sample_scaled)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    predicted_class = np.argmax(output_data[0])\n",
    "    print(f\"Input: {sample}, Scaled: {sample_scaled[0]}\")\n",
    "    print(f\"Predicted: {labels[predicted_class]}\")\n",
    "    print(f\"Probabilities: {output_data[0]}\")\n",
    "    print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
